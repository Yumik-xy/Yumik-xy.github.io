---
layout: post
title: 基于GMM-HMM的语音识别笔记（一）
date: 2021-05-26 10:00:00 +0800
categories: 语音识别
tag: 
- HMM
- GMM
---

* content
{:toc}
[数字语音处理 李琳山老师](http://speech.ee.ntu.edu.tw/DSP2019Spring/) 学习笔记

### 语音识别的三大法宝

#### 隐马尔可夫模型（HMM）

从一个简单的状态模型分析，如果我们有这样的两个模型：「模型A」和「模型B」

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210525232943.png!small" alt="image-20210525232928046" style="zoom:50%;" />

+ 模型A表示：state1有0.9的可能性切换到state2，有0.1的可能性维持在state1
+ 模型B表示：state1有0.1的可能性切换到state2，有0.9的可能性维持在state1

因此`隐马尔可夫模型HMM`就类似于我们判断的一种思维方式

🌰例如，我们看到一串通过两个模型中的一个生成的状态序列X，状态如下：

S1->S1->S1->S1->S1->S1->S2->…

我们就很理所当然的认为这一串序列是由模型B产生出来的，因为模型B在state1时有很大的概率会维持在自身，而模型A在state1时很容易就转换到了下一个状态，而这种主观意识上的判断，计算机可以通过HMM模型实现

因此当我们放在state更多的语音信号模型中时，我们将语音信号解析成为对应的状态，通过状态间的切换关系，HMM就可以判断出其最有可能符合哪一个模型，从而判断出这句语音信号的意思

#### 高斯混合模型（GMM）

图文部分引用来源 [一文详解高斯混合模型原理](https://zhuanlan.zhihu.com/p/31103654)

*高斯混合模型是对高斯模型进行简单的扩展，GMM使用多个高斯分布的组合来刻画数据分布。*

##### 高斯模型

如果我们对大量的人口进行身高数据的随机采样，绘制的到如下的柱状模型

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526081526.jpeg!small" alt="img" style="zoom:50%;" />

该模型的主要峰值集中在175\~180附近，并向两边递减，该模型就很好的匹配了高斯分布的形态，其对应拟合的高斯参数$\mu=180$与$\sigma=28$可以得到如下拟合图

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526081529.jpeg!small" alt="img" style="zoom: 67%;" />

可以看出数据拟合度很高，虽然仍有一定的误差，这些误差我们可以更进一步的参数调整使得模型更加拟合，也可以使用一个准确的算法来生成模型使得模型和实际值之间误差最小，最常用的算法是最大期望算法（EM）

##### 高斯混合模型

高斯混合模型则是通过多个高斯分布共同描述一个模型，假定我们不再考察全部用户的身高，而要在模型中同时考虑男性和女性的身高，那么我们上面的绘制的柱状图实际上是两个图的叠加结果（男性身高图和女性身高图）。而这两个图若是都满足高斯分布，则说明原图是由两个高斯分布所叠加而成，因此原图我们可以使用两个高斯模型来建模

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526082436.jpeg!small" alt="img" style="zoom:67%;" />

由于男性和女性的均值身高有所差异，即会产生不同的$\mu$与$\sigma$，通过多个不同的高斯模型对数据进行描述，就可以更好的保留原图所包含的信息，提高模型的匹配度，在语音信号模型中我们常常使用39维度的MFCC特征向量，因此也会产生39维高斯混合模型的叠加

换而言之，这些语音数据我们都可以通过39个高斯模型进行拟合叠加，而得到每一点对应的高斯混合模型对应的概率

#### 最大后验概率（MAP）

假设要预测一天的天气，天气分成三类「晴天」「雨天」和「阴天」即$W:[w_1,w_2,w_3]$

这三类天气出现的概率分别为$P(w_1)$、$P(w_2)$、$P(w_3)$，且满足$\sum_{i=1}^{3} P(w_i)=1$

并且每天我都可以收集到很多参数，例如空气湿度、气温、风向……各种参数并转化成n维向量$\overline{o}$，有统计值：$\overline{O}=(\overline{o_1},\overline{o_2},\overline{o_3},\cdots)$

那么给我今天的参数$\overline{o_n}$去求解明天的天气$W$

**解法1：**如果我知道每种天气的概率$P(w_i)$，那么明天对应天气的概率也就是$P(w_i)$

这当然是正确的，因为概率是大数统计得来的一般规律，但是猜对的概率也就只能是$P(w_i)$了，因为猜测并没有用到今天的气候参数，如果今天阴雨绵绵且一直不停，那么明天是阴天或雨天的概率应该会高于晴天的概率，因此解法1可行，但仅仅止步于此

**解法2：**求解$P(w_i\|\overline{O})$的概率分布，则最大的值也就是明天最有可能的天气

解法2求解基于今天的气象数据，求解明天天气的分布概率，解决了解法1中存在的问题。

*这种求法也就是「事后概率」即基于观测值求未知的值*

**最大后验概率：**顾名思义就是最大化在给定数据样本的情况下模型参数的后验概率，是根据已知样本，来通过调整模型参数使得模型能够产生该数据样本的概率最大

### 大词汇连续语音识别问题

#### 模型训练

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526073937.png!small" alt="语音识别模型" style="zoom:67%;" />

**对于个输入语音信号：**

This is speech

**声学模型：**

其又称为「音素」，音素是最小的语音单位，通过一个或多个音素可以组成一个音节。在汉语中「这」的音素可以是「zh,e」，在英语中「this」的音素是「th,ih,s」等

因此This is speech的音素为：th-ih-s-ih-z-s-p-ih-ch

**词典：**

词典告诉了计算机，哪些音素可以组成词汇

因此th-ih-s对应this，ih-z对应is，s-p-iy-ch对应speech

**语言模型：**

但是很多音素之间的发音是十分接近的，例如s与z的发应是非常接近的，因此计算机并不能准确识别出你发的是哪一个音，只能告诉你这个音最接近哪一个，给出一个可能性分数

因此我们还需要补充一个语言模型，这个模型会告诉计算机如果我第一个词是This，那么第二个词是is的可能性有多大，第三个词是speech的可能性有多大，这三个词同时出现的可能性有多大，通过语言模型来得到最佳匹配的语句

因此输出This is speech的几率为$P=P(This)P(is\|This)P(speech\|This\ is)$

##### HMM参数

对于每一帧时刻的帧片段，我们有特征向量：$\overline{o_t}=[x_1,x_2,\cdots,x_D]^T$，对应的状态$S_{q_t}$：$q_t\in{1,2\cdots N}$

状态转移概率：$A=[a_{ij}]$，$a_{ij}=Prob[q_t=j\|q_{t-1}=i]$，即从t-1时刻是状态S1而t时刻是状态S2的概率

观测概率：$B=[b_j(\overline{o}),j=1,2,\cdots,N]$，其中$b_j(\overline{o})=\sum_{k=1}^{M}(c_{jk}b_{jk}(\overline{o}))$，而$b_{jk}(\overline{o})$是多维度下的各个高斯分布的概率值，因此$b_j(\overline{o})$是这些概率值的叠加。$c_{jk}$是所有高斯分布的权重weight，其要满足$\sum_{k=1}^{M}(c_{jk})=1$，才能输出正确的概率

起始概率：$\pi=[\pi_1,\pi_2\,\cdots,\pi_N]$，$\pi_i=Prob[q1=i]$，即选择该点作为起始点的概率（语音输入的起始点并不固定，可以有很多个，因此不同的起始点会影响后面的判决）

因此HMM输入输出：$HMM(A,B,\pi)=\lambda$

### 语音处理

#### 特征提取（端点处理算法）

+ 高频部分预增强：高频段的振幅往往较小，提高高频段便于学习

  $H(z)=1-az^{-1}$，$0\ll a<1$

+ 端点检测：有声段/无声段检测，去除多余的信号，减少机器学习的负担

  + 短时帧能量
  + 短时帧过零点数

+ 加Hamming窗：柔滑过渡段语音信号

  $w[m]=\left\\{\begin{matrix}0.54-0.46cos[\frac{2\pi m}{L}],0\leq m\leq L-1\\\\ 0,else \end{matrix}\right.$
  
+ MFCC特征提取：将「时间域的信号特征」转化成「频域的信号特征」

  + 加窗后的短时帧信号
  + 傅里叶变换
  + 经过Mel滤波器
  + 做绝对值平方的对数
  + 做逆离散傅里叶变换IDFT
  + 得到MFCC

  得到的MFCC只有13维信息，我们要继续求解一次微分和两次微分得到39维信息

#### 语言模型

让计算机读取非常多的文章，让它学到这些词句两两相连、三三相连的几率帮助得到整个句子的几率

例如：计算机根据输入语音对每一个词判决如下：$W=(\begin{bmatrix}w_{11}\\\\ w_{12}\\\\ \vdots\\\\ w_{1n}\end{bmatrix},\begin{bmatrix}w_{21}\\\\ w_{22}\\\\ \vdots\\\\ w_{2n}\end{bmatrix},\cdots,\begin{bmatrix}w_{k1}\\\\ w_{k2}\\\\ \vdots\\\\ w_{kn}\end{bmatrix})$，$w_{ij}$表示第i个词可能为第j词（假设第一个词发应为wo，计算机可以判决为：我、沃……）

那么计算机就要去判决这些词两两组合，三三组合成为一整个句子的概率，若是第二个词发音为xi’huan，同理计算机可以判决为：喜欢、西环，但是根据前后文组合，「我-喜欢」成为一组的可能性会远高于其他组别，因此判决这句话为「我喜欢……」的概率就会更高

计算机会去判决所有可能的组合，选择出可能性最高的一组做为语句的输出，而这样一个前后文学习的积累，就是通过语言模型来建立的

如去读取了几千几万个网页，读取到的信息如下：

|     词句     | 频率  |
| :----------: | :---: |
|   … this …   | 50000 |
| … this is …  |  500  |
| … this is a… |  50   |

因此`is`出现在`this`后面的概率则为$Prob(is\|this)=\frac{500}{50000}$，`a`出现在`this is`后面的概率为$Prob(a\|this\ is)=\frac{50}{500}$，这便是两两一组/三三一组词语同时出现的的概率计算公式

但是这也存在一个问题，如果this is speech这句话在所有的检索中几乎没有出现，或者出现的概率非常低，那么机器在判别的时候就会认为这句话几乎不可能出现。可语言是十分丰富的，存在着大量的词句构造而成，我们必须加入更多的判决方式来优化，防止那些出现次数很低的词组被计算机直接抛弃

#### 基于音节的单程搜索

通过之前构建的声学模型、词典和语言模型3种从未知输入语音中寻找最优句子

<img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526142905.png!small" alt="image-20210526142905532" style="zoom: 50%;" />

+ **进行音节分帧**

  比如从语音帧开始发现，有3种可能构成的音节，例如第一个是「ji」，第二个是「jin」，第三个是「jing」但是计算机并不能确定是哪一个，于是这三种都保留下来，并得出相应的概率，并以此为基础向后继续寻找音节

  <img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526143026.png!small" alt="image-20210526143026253" style="zoom: 50%;" />

  

+ **进行词分帧**

  通过分割出的音节帧，计算机发现这两个音节帧恰好组成一个词组，例如$w_1=「jin」+「tian」$符合词典模型中的用法，接着继续往后寻找下一个词$w_2,w_3$，当然也可能有其他的组合方式，这就形成了词分帧

  <img src="https://yumik-xy.oss-cn-qingdao.aliyuncs.com/img/20210526143705.png!small" alt="image-20210526143705823" style="zoom:50%;" />

+ **进行句分帧**

  上面分割出的词帧，就要匹配语言模型，判断哪些词能构成一个完整的句子，则这一组词的可能性就会很高，最后根据所有词分帧得到的成句概率输出最优值，即为最优输出句
